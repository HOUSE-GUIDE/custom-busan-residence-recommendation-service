# import pandas as pd
# import os
# from sklearn.metrics.pairwise import cosine_similarity
# import numpy as np

# facility_list = ['ì§€í•˜ì² ì—­','ëŒ€í˜•ë§ˆíŠ¸','ìœ ì¹˜ì›','ê²½ì°°ì„œ','ì¢…í•©ë³‘ì›','ì†Œë°©ì„œ','ë„ì‹œê·¼ë¦°ê³µì›','í•´ìˆ˜ìš•ì¥','ëŒ€í•™êµ']

# base_dir = 'data/í–‰ì •êµ¬ë³„_data'

# directory_list = [os.path.join(base_dir, 'ê¸ˆì •êµ¬'), os.path.join(base_dir, 'ë‚¨êµ¬'), os.path.join(base_dir, 'ë™êµ¬'), os.path.join(base_dir, 'ë™ë˜êµ¬'), os.path.join(base_dir, 'ë¶€ì‚°ì§„êµ¬'), os.path.join(base_dir, 'ë¶êµ¬'), os.path.join(base_dir, 'ì‚¬ìƒêµ¬'), os.path.join(base_dir, 'ì‚¬í•˜êµ¬'), os.path.join(base_dir, 'ì„œêµ¬'), os.path.join(base_dir, 'ìˆ˜ì˜êµ¬'), os.path.join(base_dir, 'ì—°ì œêµ¬'), os.path.join(base_dir, 'ì˜ë„êµ¬'), os.path.join(base_dir, 'ì¤‘êµ¬'), os.path.join(base_dir, 'í•´ìš´ëŒ€êµ¬'),]

# dong_list = []
# for directory in directory_list:
#     for file_name in os.listdir(directory):
#         dong = file_name.split('_')[0]
#         if dong not in dong_list:
#             dong_list.append(dong)

# df_matrix = pd.DataFrame(index=dong_list, columns=facility_list)

# for directory in directory_list:
#     for file_name in os.listdir(directory):
#         dong, facility = file_name.split('_')[0], file_name.split('_')[1].replace('.csv', '')
#         df=pd.read_csv(os.path.join(directory, file_name))
#         df_matrix.loc[dong, facility] = len(df)

# def calculate_similarity(user_weights):
#     category_weights = {
#         'traffic': np.mean([user_weights.get(f'traffic{i}', 0) for i in range(1, 6)]),
#         'education': np.mean([user_weights.get(f'education{i}', 0) for i in range(1, 6)]),
#         'nature': np.mean([user_weights.get(f'nature{i}', 0) for i in range(1, 6)]),
#         'shopping': np.mean([user_weights.get(f'shopping{i}', 0) for i in range(1, 6)]),
#         'society': np.mean([user_weights.get(f'society{i}', 0) for i in range(1, 6)])
#     }

#     facility_weights = {
#         'ì§€í•˜ì² ì—­': category_weights['traffic'],
#         'ëŒ€í˜•ë§ˆíŠ¸': category_weights['shopping'],
#         'ìœ ì¹˜ì›': category_weights['education'],
#         'ê²½ì°°ì„œ': category_weights['society'],
#         'ì¢…í•©ë³‘ì›': category_weights['society'],
#         'ì†Œë°©ì„œ': category_weights['society'],
#         'ë„ì‹œê·¼ë¦°ê³µì›': category_weights['nature'],
#         'í•´ìˆ˜ìš•ì¥': category_weights['nature'],
#         'ëŒ€í•™êµ': category_weights['education']
#     }

#     user_weights_expanded = np.array([facility_weights.get(facility, 0) for facility in df_matrix.columns])
#     user_weights_expanded = user_weights_expanded / np.sum(user_weights_expanded)

#     print(user_weights_expanded)

#     df_matrix_weighted = df_matrix.mul(user_weights_expanded, axis=1)
#     print(df_matrix_weighted)

#     similarity_matrix = cosine_similarity(df_matrix_weighted)
#     print(similarity_matrix)

#     # ì‚¬ìš©ì ê°€ì¤‘ì¹˜ì™€ ê° ë™ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
#     user_weights_expanded_2d = user_weights_expanded[np.newaxis, :]  # 2ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜
#     user_dong_similarity = cosine_similarity(user_weights_expanded_2d, df_matrix_weighted)[0]  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„

#     # ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ë™ 3ê°œ ì¶”ì¶œ
#     top3_dong_index = user_dong_similarity.argsort()[-3:][::-1]
#     top3_dong = df_matrix.index[top3_dong_index]

#     return top3_dong

# # test ë°ì´í„°, í”„ë¡ íŠ¸ì—ì„œ ì…ë ¥ë°›ì„ ê°€ì¤‘ì¹˜ë“¤ì„ ì„ì˜ë¡œ ë°°ì •í•œ ê²ƒì„ë‹¹ğŸ˜€
# user_weights = { 
#     'traffic1': 1,
#     'traffic2': 1,
#     'traffic3': 2,
#     'traffic4': 3,
#     'traffic5': 3,
#     'education1': 1,
#     'education2': 1,
#     'education3': 1,
#     'education4': 3,
#     'education5': 4,
#     'nature1': 1,
#     'nature2': 1,
#     'nature3': 1,
#     'nature4': 1,
#     'nature5': 1,
#     'shopping1': 1,
#     'shopping2': 1,
#     'shopping3': 1,
#     'shopping4': 1,
#     'shopping5': 1,
#     'society1': 4,
#     'society2': 5,
#     'society3': 1,
#     'society4': 1,
#     'society5': 1
# }

# top3_dong = calculate_similarity(user_weights)
# print(top3_dong)


import pandas as pd
import os
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

facility_list = ['ì§€í•˜ì² ì—­','ëŒ€í˜•ë§ˆíŠ¸','ìœ ì¹˜ì›','ê²½ì°°ì„œ','ì¢…í•©ë³‘ì›','ì†Œë°©ì„œ','ë„ì‹œê·¼ë¦°ê³µì›','í•´ìˆ˜ìš•ì¥','ëŒ€í•™êµ']

base_dir = 'data/í–‰ì •êµ¬ë³„_data'

directory_list = [os.path.join(base_dir, 'ê¸ˆì •êµ¬'), os.path.join(base_dir, 'ë‚¨êµ¬'), os.path.join(base_dir, 'ë™êµ¬'), os.path.join(base_dir, 'ë™ë˜êµ¬'), os.path.join(base_dir, 'ë¶€ì‚°ì§„êµ¬'), os.path.join(base_dir, 'ë¶êµ¬'), os.path.join(base_dir, 'ì‚¬ìƒêµ¬'), os.path.join(base_dir, 'ì‚¬í•˜êµ¬'), os.path.join(base_dir, 'ì„œêµ¬'), os.path.join(base_dir, 'ìˆ˜ì˜êµ¬'), os.path.join(base_dir, 'ì—°ì œêµ¬'), os.path.join(base_dir, 'ì˜ë„êµ¬'), os.path.join(base_dir, 'ì¤‘êµ¬'), os.path.join(base_dir, 'í•´ìš´ëŒ€êµ¬'),]

dong_list = []
for directory in directory_list:
    for file_name in os.listdir(directory):
        dong = file_name.split('_')[0]
        if dong not in dong_list:
            dong_list.append(dong)

df_matrix = pd.DataFrame(index=dong_list, columns=facility_list)

for directory in directory_list:
    for file_name in os.listdir(directory):
        dong, facility = file_name.split('_')[0], file_name.split('_')[1].replace('.csv', '')
        df=pd.read_csv(os.path.join(directory, file_name))
        df_matrix.loc[dong, facility] = len(df)

def calculate_similarity(user_weights):
    category_weights = {
        'traffic': np.mean([user_weights.get(f'traffic{i}', 0) for i in range(1, 6)]),
        'education': np.mean([user_weights.get(f'education{i}', 0) for i in range(1, 6)]),
        'nature': np.mean([user_weights.get(f'nature{i}', 0) for i in range(1, 6)]),
        'shopping': np.mean([user_weights.get(f'shopping{i}', 0) for i in range(1, 6)]),
        'society': np.mean([user_weights.get(f'society{i}', 0) for i in range(1, 6)])
    }

    facility_weights = {
        'ì§€í•˜ì² ì—­': category_weights['traffic'],
        'ëŒ€í˜•ë§ˆíŠ¸': category_weights['shopping'],
        'ìœ ì¹˜ì›': category_weights['education'],
        'ê²½ì°°ì„œ': category_weights['society'],
        'ì¢…í•©ë³‘ì›': category_weights['society'],
        'ì†Œë°©ì„œ': category_weights['society'],
        'ë„ì‹œê·¼ë¦°ê³µì›': category_weights['nature'],
        'í•´ìˆ˜ìš•ì¥': category_weights['nature'],
        'ëŒ€í•™êµ': category_weights['education']
    }

    user_weights_expanded = np.array([facility_weights.get(facility, 0) for facility in df_matrix.columns])
    user_weights_expanded = user_weights_expanded / np.sum(user_weights_expanded)

    df_matrix_weighted = df_matrix.mul(user_weights_expanded, axis=1)

    similarity_matrix = cosine_similarity(df_matrix_weighted)

    # ì‚¬ìš©ì ê°€ì¤‘ì¹˜ì™€ ê° ë™ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    user_weights_expanded_2d = user_weights_expanded[np.newaxis, :]  # 2ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜
    user_dong_similarity = cosine_similarity(user_weights_expanded_2d, df_matrix_weighted)[0]  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„

    # ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ë™ 3ê°œ ì¶”ì¶œ
    top3_dong_index = user_dong_similarity.argsort()[-3:][::-1]
    top3_dong = df_matrix.index[top3_dong_index]

    return top3_dong
