# import pandas as pd
# import os
# from sklearn.metrics.pairwise import cosine_similarity
# import numpy as np

# facility_list = ['ì§€í•˜ì² ì—­','ëŒ€í˜•ë§ˆíŠ¸','ìœ ì¹˜ì›','ê²½ì°°ì„œ','ì¢…í•©ë³‘ì›','ì†Œë°©ì„œ','ë„ì‹œê·¼ë¦°ê³µì›','í•´ìˆ˜ìš•ì¥','ëŒ€í•™êµ']

# # csv íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŠ¸ (ê° êµ¬ë³„ë¡œ ë¶„ë¥˜ëœ í´ë”)
# # directory_list = ['ê¸ˆì •êµ¬','ë‚¨êµ¬','ë™êµ¬','ë™ë˜êµ¬','ë¶€ì‚°ì§„êµ¬','ë¶êµ¬','ì‚¬ìƒêµ¬','ì‚¬í•˜êµ¬','ì„œêµ¬','ìˆ˜ì˜êµ¬','ì—°ì œêµ¬','ì˜ë„êµ¬','ì¤‘êµ¬','í•´ìš´ëŒ€êµ¬']  # êµ¬ í´ë” ì´ë¦„~~ ê¸°ì¥ ê°•ì„œ ì œì™¸

# base_dir = 'data/í–‰ì •êµ¬ë³„_data'

# directory_list = [os.path.join(base_dir, 'ê¸ˆì •êµ¬'), os.path.join(base_dir, 'ë‚¨êµ¬'), os.path.join(base_dir, 'ë™êµ¬'), os.path.join(base_dir, 'ë™ë˜êµ¬'), os.path.join(base_dir, 'ë¶€ì‚°ì§„êµ¬'), os.path.join(base_dir, 'ë¶êµ¬'), os.path.join(base_dir, 'ì‚¬ìƒêµ¬'), os.path.join(base_dir, 'ì‚¬í•˜êµ¬'), os.path.join(base_dir, 'ì„œêµ¬'), os.path.join(base_dir, 'ìˆ˜ì˜êµ¬'), os.path.join(base_dir, 'ì—°ì œêµ¬'), os.path.join(base_dir, 'ì˜ë„êµ¬'), os.path.join(base_dir, 'ì¤‘êµ¬'), os.path.join(base_dir, 'í•´ìš´ëŒ€êµ¬'),]


# # ê° í´ë”ì—ì„œ ë™ ë¦¬ìŠ¤íŠ¸ ìƒì„±
# print("ì‹œìŠ¤í…œ ì‹œì‘")
# dong_list = []
# for directory in directory_list:
#     for file_name in os.listdir(directory):
#         dong = file_name.split('_')[0]
#         if dong not in dong_list:
#             dong_list.append(dong)

# # ê° ë™ë³„ ì‹œì„¤ì˜ ê°œìˆ˜ë¥¼ ë‹´ì„ ë°ì´í„°í”„ë ˆì„
# df_matrix = pd.DataFrame(index=dong_list, columns=facility_list)

# for directory in directory_list:
#     for file_name in os.listdir(directory):
#         dong, facility = file_name.split('_')[0], file_name.split('_')[1].replace('.csv', '')
#         df=pd.read_csv(os.path.join(directory, file_name))
#         df_matrix.loc[dong, facility] = len(df)

# print("ê°€ì¤‘ì¹˜ ê³„ì‚° ì‹œì‘")


# def calculate_similarity(user_weights):
#     # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê°€ì¤‘ì¹˜ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‰ê· ë‚´ì–´ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°
#     category_weights = {
#         'traffic': np.mean([user_weights.get(f'traffic{i}', 0) for i in range(1, 4)]),
#         'education': np.mean([user_weights.get(f'education{i}', 0) for i in range(1, 4)]),
#         'nature': np.mean([user_weights.get(f'nature{i}', 0) for i in range(1, 4)]),
#         'shopping': np.mean([user_weights.get(f'shopping{i}', 0) for i in range(1, 4)]),
#         'society': np.mean([user_weights.get(f'society{i}', 0) for i in range(1, 4)])
#     }

#     # ê° ì¹´í…Œê³ ë¦¬ì˜ ê°€ì¤‘ì¹˜ë¥¼ í•´ë‹¹ ì‹œì„¤ì— ëŒ€ì‘
#     facility_weights = {
#         'ì§€í•˜ì² ì—­': category_weights['traffic'],
#         'ëŒ€í˜•ë§ˆíŠ¸': category_weights['shopping'],
#         'ìœ ì¹˜ì›': category_weights['education'],
#         'ê²½ì°°ì„œ': category_weights['society'],
#         'ì¢…í•©ë³‘ì›': category_weights['society'],
#         'ì†Œë°©ì„œ': category_weights['society'],
#         'ë„ì‹œê·¼ë¦°ê³µì›': category_weights['nature'],
#         'í•´ìˆ˜ìš•ì¥': category_weights['nature'],
#         'ëŒ€í•™êµ': category_weights['education']
#     }

#     # ì‚¬ìš©ìì˜ ê°€ì¤‘ì¹˜ì— ë”°ë¼ ë™ë³„ ì‹œì„¤ ì ìˆ˜ ê³„ì‚°
#     user_weights_expanded = np.array([facility_weights.get(facility, 0) for facility in df_matrix.columns])
#     user_weights_expanded = user_weights_expanded / np.sum(user_weights_expanded)  # ì •ê·œí™”

#     print(user_weights_expanded)  # ë””ë²„ê¹…ìš©: user_weights_expanded ì¶œë ¥

#     # ì‚¬ìš©ìì˜ ê°€ì¤‘ì¹˜ë¡œ df_matrixë¥¼ ì¡°ì •
#     df_matrix_weighted = df_matrix.mul(user_weights_expanded, axis=1)
#     print(df_matrix_weighted)  # ë””ë²„ê¹…ìš©: df_matrix_weighted ì¶œë ¥

#     # ë™ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
#     similarity_matrix = cosine_similarity(df_matrix_weighted)
#     print(similarity_matrix)  # ë””ë²„ê¹…ìš©: similarity_matrix ì¶œë ¥

#     # ì‚¬ìš©ì ê°€ì¤‘ì¹˜ì™€ ê° ë™ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
#     user_dong_similarity = similarity_matrix @ user_weights_expanded

#     # ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ë™ 3ê°œ ì¶”ì¶œ
#     top3_dong_index = user_dong_similarity.argsort()[-3:][::-1]
#     top3_dong = df_matrix.index[top3_dong_index]

#     return top3_dong

# print("ì½”ë“œ ë")




import pandas as pd
import os
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

facility_list = ['ì§€í•˜ì² ì—­','ëŒ€í˜•ë§ˆíŠ¸','ìœ ì¹˜ì›','ê²½ì°°ì„œ','ì¢…í•©ë³‘ì›','ì†Œë°©ì„œ','ë„ì‹œê·¼ë¦°ê³µì›','í•´ìˆ˜ìš•ì¥','ëŒ€í•™êµ']

base_dir = 'data/í–‰ì •êµ¬ë³„_data'

directory_list = [os.path.join(base_dir, 'ê¸ˆì •êµ¬'), os.path.join(base_dir, 'ë‚¨êµ¬'), os.path.join(base_dir, 'ë™êµ¬'), os.path.join(base_dir, 'ë™ë˜êµ¬'), os.path.join(base_dir, 'ë¶€ì‚°ì§„êµ¬'), os.path.join(base_dir, 'ë¶êµ¬'), os.path.join(base_dir, 'ì‚¬ìƒêµ¬'), os.path.join(base_dir, 'ì‚¬í•˜êµ¬'), os.path.join(base_dir, 'ì„œêµ¬'), os.path.join(base_dir, 'ìˆ˜ì˜êµ¬'), os.path.join(base_dir, 'ì—°ì œêµ¬'), os.path.join(base_dir, 'ì˜ë„êµ¬'), os.path.join(base_dir, 'ì¤‘êµ¬'), os.path.join(base_dir, 'í•´ìš´ëŒ€êµ¬'),]

dong_list = []
for directory in directory_list:
    for file_name in os.listdir(directory):
        dong = file_name.split('_')[0]
        if dong not in dong_list:
            dong_list.append(dong)

df_matrix = pd.DataFrame(index=dong_list, columns=facility_list)

for directory in directory_list:
    for file_name in os.listdir(directory):
        dong, facility = file_name.split('_')[0], file_name.split('_')[1].replace('.csv', '')
        df=pd.read_csv(os.path.join(directory, file_name))
        df_matrix.loc[dong, facility] = len(df)

def calculate_similarity(user_weights):
    category_weights = {
        'traffic': np.mean([user_weights.get(f'traffic{i}', 0) for i in range(1, 5)]),
        'education': np.mean([user_weights.get(f'education{i}', 0) for i in range(1, 4)]),
        'nature': np.mean([user_weights.get(f'nature{i}', 0) for i in range(1, 6)]),
        'shopping': np.mean([user_weights.get(f'shopping{i}', 0) for i in range(1, 4)]),
        'society': np.mean([user_weights.get(f'society{i}', 0) for i in range(1, 4)])
    }

    facility_weights = {
        'ì§€í•˜ì² ì—­': category_weights['traffic'],
        'ëŒ€í˜•ë§ˆíŠ¸': category_weights['shopping'],
        'ìœ ì¹˜ì›': category_weights['education'],
        'ê²½ì°°ì„œ': category_weights['society'],
        'ì¢…í•©ë³‘ì›': category_weights['society'],
        'ì†Œë°©ì„œ': category_weights['society'],
        'ë„ì‹œê·¼ë¦°ê³µì›': category_weights['nature'],
        'í•´ìˆ˜ìš•ì¥': category_weights['nature'],
        'ëŒ€í•™êµ': category_weights['education']
    }

    user_weights_expanded = np.array([facility_weights.get(facility, 0) for facility in df_matrix.columns])
    user_weights_expanded = user_weights_expanded / np.sum(user_weights_expanded)

    print(user_weights_expanded)

    df_matrix_weighted = df_matrix.mul(user_weights_expanded, axis=1)
    print(df_matrix_weighted)

    similarity_matrix = cosine_similarity(df_matrix_weighted)
    print(similarity_matrix)

    # ì‚¬ìš©ì ê°€ì¤‘ì¹˜ì™€ ê° ë™ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    user_weights_expanded_2d = user_weights_expanded[np.newaxis, :]  # 2ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜
    user_dong_similarity = cosine_similarity(user_weights_expanded_2d, df_matrix_weighted)[0]  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„

    # ìœ ì‚¬ë„ê°€ ê°€ì¥ ë†’ì€ ë™ 3ê°œ ì¶”ì¶œ
    top3_dong_index = user_dong_similarity.argsort()[-3:][::-1]
    top3_dong = df_matrix.index[top3_dong_index]

    return top3_dong

# test ë°ì´í„°, í”„ë¡ íŠ¸ì—ì„œ ì…ë ¥ë°›ì„ ê°€ì¤‘ì¹˜ë“¤ì„ ì„ì˜ë¡œ ë°°ì •í•œ ê²ƒì„ë‹¹ğŸ˜€
user_weights = { 
    'traffic1': 1,
    'traffic2': 1,
    'traffic3': 2,
    'traffic4': 3,
    'education1': 1,
    'education2': 1,
    'education3': 1,
    'nature1': 4,
    'nature2': 4,
    'nature3': 3,
    'nature4': 5,
    'nature5': 5,
    'shopping1': 3,
    'shopping2': 1,
    'shopping3': 4,
    'society1': 4,
    'society2': 5,
    'society3': 1
}

top3_dong = calculate_similarity(user_weights)
print(top3_dong)
